[{'text': "SPEAKER 1: Unless you've\nbeen living under a rock,", 'start': 0.0, 'duration': 1.84}, {'text': "you've probably heard\nthat AI is getting", 'start': 1.84, 'duration': 1.667}, {'text': 'very good at conversation.', 'start': 3.507, 'duration': 1.426}, {'text': 'In fact, maybe you\neven chatted with one', 'start': 4.933, 'duration': 1.667}, {'text': "of these AI's through a chat\nbot interface like Google Bard.", 'start': 6.6, 'duration': 3.0}, {'text': 'SPEAKER 2: This is all\nthanks to a powerful kind', 'start': 9.6, 'duration': 2.01}, {'text': 'of neural network called a\nLarge Language Model, or LLM.', 'start': 11.61, 'duration': 4.13}, {'text': 'LLMs enable computers to\nunderstand and generate', 'start': 15.74, 'duration': 2.95}, {'text': 'language better\nthan ever before,', 'start': 18.69, 'duration': 1.8}, {'text': 'unlocking a whole host\nof new applications.', 'start': 20.49, 'duration': 2.508}, {'text': "SPEAKER 1: In this\nvideo, we're going", 'start': 22.998, 'duration': 1.542}, {'text': 'to talk about what LLMs\nare and how anyone can get', 'start': 24.54, 'duration': 2.083}, {'text': "started building with them,\nwhether you're a developer", 'start': 26.623, 'duration': 2.25}, {'text': 'or not.', 'start': 28.873, 'duration': 0.587}, {'text': 'SPEAKER 2: Ready?', 'start': 29.46, 'duration': 0.84}, {'text': "BOTH: Let's dive in.", 'start': 30.3, 'duration': 2.668}, {'text': 'SPEAKER 1: LLMs are\nmachine learning models', 'start': 32.968, 'duration': 1.792}, {'text': 'that are really good at\nunderstanding and generating', 'start': 34.76, 'duration': 2.167}, {'text': 'human language.', 'start': 36.927, 'duration': 0.683}, {'text': "They're based on transformers,\na type of neural network", 'start': 37.61, 'duration': 2.34}, {'text': 'architecture invented by Google.', 'start': 39.95, 'duration': 1.77}, {'text': 'Now, what made the transformer\narchitecture so powerful', 'start': 41.72, 'duration': 2.85}, {'text': 'was its ability to\nscale effectively,', 'start': 44.57, 'duration': 1.86}, {'text': 'allowing us to train these\nmodels on massive text', 'start': 46.43, 'duration': 2.13}, {'text': 'datasets.', 'start': 48.56, 'duration': 0.72}, {'text': 'SPEAKER 2: That\'s where the\n"large" in large language', 'start': 49.28, 'duration': 2.208}, {'text': 'models comes from--', 'start': 51.488, 'duration': 0.832}, {'text': 'both the size and complexity\nof the neural network itself,', 'start': 52.32, 'duration': 2.84}, {'text': 'as well as the size of the\ndataset that it was trained on.', 'start': 55.16, 'duration': 3.0}, {'text': "For some of these\nmodels, we're talking", 'start': 58.16, 'duration': 1.68}, {'text': 'about trillions of\ntokens from a bunch', 'start': 59.84, 'duration': 2.04}, {'text': 'of publicly available sources.', 'start': 61.88, 'duration': 2.189}, {'text': "And it wasn't until\nresearchers started", 'start': 64.069, 'duration': 1.681}, {'text': 'to make these\nmodels really large', 'start': 65.75, 'duration': 1.71}, {'text': 'and train them on\nthese huge datasets', 'start': 67.46, 'duration': 1.92}, {'text': 'that they started showing\nthese impressive results,', 'start': 69.38, 'duration': 2.4}, {'text': 'like understanding complex,\nnuanced language and generating', 'start': 71.78, 'duration': 3.72}, {'text': 'language more\neloquently than ever.', 'start': 75.5, 'duration': 1.89}, {'text': "SPEAKER 1: If you're already\nfamiliar with machine learning,", 'start': 77.39, 'duration': 2.5}, {'text': 'you probably think\nabout training', 'start': 79.89, 'duration': 1.375}, {'text': 'a model for a\nspecific task, like is', 'start': 81.265, 'duration': 2.395}, {'text': 'this tweet positive or\nnegative, or translate this text', 'start': 83.66, 'duration': 2.79}, {'text': 'from French to English.', 'start': 86.45, 'duration': 2.11}, {'text': 'What makes LLMs\nespecially powerful', 'start': 88.56, 'duration': 2.12}, {'text': 'is that one model can be used\nfor a whole variety of tasks,', 'start': 90.68, 'duration': 2.73}, {'text': 'like chat, copywriting,\ntranslation, summarization,', 'start': 93.41, 'duration': 3.57}, {'text': 'brainstorming, code generation,\nand a whole lot more.', 'start': 96.98, 'duration': 2.805}, {'text': 'SPEAKER 2: Best of all, you can\nprototype language applications', 'start': 99.785, 'duration': 2.625}, {'text': 'incredibly fast with LLMs--', 'start': 102.41, 'duration': 1.98}, {'text': 'in just minutes,\nrather than months.', 'start': 104.39, 'duration': 1.757}, {'text': "And you don't have to be\na machine learning expert", 'start': 106.147, 'duration': 2.083}, {'text': 'to do it.', 'start': 108.23, 'duration': 0.9}, {'text': 'All you really need to\nknow is how to write.', 'start': 109.13, 'duration': 2.55}, {'text': 'So how do you\nactually use an LLM?', 'start': 111.68, 'duration': 2.01}, {'text': "Well, let's take a look.", 'start': 113.69, 'duration': 1.85}, {'text': 'LLMs learn about\npatterns and language', 'start': 115.54, 'duration': 2.17}, {'text': "from the massive amounts of\ntext data they're trained on.", 'start': 117.71, 'duration': 2.7}, {'text': 'Then they take as\ninput some text', 'start': 120.41, 'duration': 2.28}, {'text': "and produce some output text\nthat's likely to follow.", 'start': 122.69, 'duration': 2.633}, {'text': 'SPEAKER 1: Another\nway to say this', 'start': 125.323, 'duration': 1.417}, {'text': 'is that LLMs are like really\nsophisticated autocomplete.', 'start': 126.74, 'duration': 2.94}, {'text': 'So for example, if we\ngive an LLM the input--', 'start': 129.68, 'duration': 2.61}, {'text': "SPEAKER 2: It's\nraining cats and--", 'start': 132.29, 'duration': 1.48}, {'text': 'SPEAKER 1: It\'ll probably\npredict that "dogs" is', 'start': 133.77, 'duration': 2.0}, {'text': 'the most likely word to follow.', 'start': 135.77, 'duration': 1.68}, {'text': 'Now, this might not\nseem that exciting,', 'start': 137.45, 'duration': 1.8}, {'text': 'but we can actually use this\nautocomplete-like functionality', 'start': 139.25, 'duration': 2.88}, {'text': 'to solve tons of tasks just by\nwriting strategic text input.', 'start': 142.13, 'duration': 3.51}, {'text': "SPEAKER 2: For example,\nlet's take Google's PaLM", 'start': 145.64, 'duration': 2.37}, {'text': 'LLM and input this sentence.', 'start': 148.01, 'duration': 2.048}, {'text': 'SPEAKER 1: I have two\napples and I eat one.', 'start': 150.058, 'duration': 1.792}, {'text': "I'm left with--", 'start': 151.85, 'duration': 1.14}, {'text': 'SPEAKER 2: The PaLM model\noutputs the answer "one."', 'start': 152.99, 'duration': 2.34}, {'text': 'In this way, we get the LLM\nto perform some simple math.', 'start': 155.33, 'duration': 3.282}, {'text': 'SPEAKER 1: Or take\nanother example.', 'start': 158.612, 'duration': 1.458}, {'text': 'SPEAKER 2: Paris is to\nFrance as Tokyo is to--', 'start': 160.07, 'duration': 3.87}, {'text': 'SPEAKER 1: The PaLM model\noutputs "Japan," which tells us', 'start': 163.94, 'duration': 2.4}, {'text': 'that the model can not\nonly complete analogies,', 'start': 166.34, 'duration': 2.013}, {'text': "but it also has some\nworld knowledge that it's", 'start': 168.353, 'duration': 1.917}, {'text': 'learned from its training data.', 'start': 170.27, 'duration': 2.07}, {'text': 'So I should add the\ncaveat that not all', 'start': 172.34, 'duration': 1.68}, {'text': 'of the knowledge\nthat the LLM outputs', 'start': 174.02, 'duration': 1.62}, {'text': 'is necessarily\nfactually accurate.', 'start': 175.64, 'duration': 2.16}, {'text': 'SPEAKER 2: Now, all of the\ntext that we feed into an LLM', 'start': 177.8, 'duration': 2.64}, {'text': 'as input is called a\nprompt, and it turns out', 'start': 180.44, 'duration': 2.76}, {'text': "there's this whole art known\nas prompt design, which", 'start': 183.2, 'duration': 2.58}, {'text': 'is about figuring out\nhow to write and format', 'start': 185.78, 'duration': 2.1}, {'text': 'prompt text to get LLMs\nto do what you want.', 'start': 187.88, 'duration': 2.937}, {'text': 'SPEAKER 1: For example,\none way to structure', 'start': 190.817, 'duration': 1.833}, {'text': 'a prompt is as an\ninstruction, like--', 'start': 192.65, 'duration': 2.1}, {'text': 'SPEAKER 2: Write me a\npoem about Ada Lovelace', 'start': 194.75, 'duration': 2.1}, {'text': 'in the style of Shakespeare.', 'start': 196.85, 'duration': 2.28}, {'text': "SPEAKER 1: Or explain quantum\nphysics to me like I'm five.", 'start': 199.13, 'duration': 3.157}, {'text': 'SPEAKER 2: Or generate\na list of items', 'start': 202.287, 'duration': 1.583}, {'text': 'I need for a camping trip\nto Yosemite National Park.', 'start': 203.87, 'duration': 3.18}, {'text': 'SPEAKER 1: This approach--\nusing a single command', 'start': 207.05, 'duration': 2.07}, {'text': 'to get an LLM to\ntake on a behavior--', 'start': 209.12, 'duration': 1.65}, {'text': 'is called zero shot learning.', 'start': 210.77, 'duration': 1.98}, {'text': 'But in addition to just\nproviding an instruction,', 'start': 212.75, 'duration': 2.19}, {'text': 'it can be helpful to\nshow the model what', 'start': 214.94, 'duration': 1.667}, {'text': 'you want by adding examples.', 'start': 216.607, 'duration': 1.433}, {'text': 'This is called few shot\nlearning because we showed', 'start': 218.04, 'duration': 2.083}, {'text': 'the model a few examples.', 'start': 220.123, 'duration': 1.237}, {'text': "Like here's a prompt for\ntranslating from English", 'start': 221.36, 'duration': 2.13}, {'text': 'to French.', 'start': 223.49, 'duration': 1.14}, {'text': 'First we provide an instruction.', 'start': 224.63, 'duration': 2.37}, {'text': 'Then we give some examples,\nestablishing the text pattern.', 'start': 227.0, 'duration': 4.5}, {'text': 'If we pass this prompt\nto an LLM like PaLM,', 'start': 231.5, 'duration': 2.22}, {'text': 'we get back something\nlike the following.', 'start': 233.72, 'duration': 2.52}, {'text': 'SPEAKER 2: The model did\nprovide a French translation', 'start': 236.24, 'duration': 2.25}, {'text': 'of lipstick, but you might\nnotice that it went on', 'start': 238.49, 'duration': 2.4}, {'text': 'to generate all these additional\nEnglish-French translation', 'start': 240.89, 'duration': 2.79}, {'text': 'pairs.', 'start': 243.68, 'duration': 0.72}, {'text': 'This might seem a\nlittle unexpected,', 'start': 244.4, 'duration': 1.83}, {'text': 'but the LLM is just\ncompleting the pattern', 'start': 246.23, 'duration': 2.19}, {'text': 'that we gave it in the prompt.', 'start': 248.42, 'duration': 2.04}, {'text': "As another example,\nhere's a few shot", 'start': 250.46, 'duration': 1.92}, {'text': 'prompt to convert Python\ncode snippets to JavaScript.', 'start': 252.38, 'duration': 3.21}, {'text': 'Our prompt starts\nwith an instruction,', 'start': 255.59, 'duration': 2.61}, {'text': 'then we have some examples,\nand finally, the Python code', 'start': 258.2, 'duration': 3.509}, {'text': 'we actually want converted.', 'start': 261.709, 'duration': 2.221}, {'text': 'The very last part\nof this prompt', 'start': 263.93, 'duration': 1.53}, {'text': 'is JavaScript colon\nbecause we want', 'start': 265.46, 'duration': 2.25}, {'text': 'to nudge the model to output\nsome JavaScript code just', 'start': 267.71, 'duration': 3.24}, {'text': 'like this.', 'start': 270.95, 'duration': 1.028}, {'text': 'SPEAKER 1: Note that\nin a real application,', 'start': 271.978, 'duration': 1.792}, {'text': 'we probably want to parameterize\nthe input instead of hard', 'start': 273.77, 'duration': 2.43}, {'text': 'coding it into the prompt.', 'start': 276.2, 'duration': 1.083}, {'text': 'That way, our users can\nprovide the Python code', 'start': 277.283, 'duration': 2.157}, {'text': 'that they want converted.', 'start': 279.44, 'duration': 1.77}, {'text': 'And this is essentially how\nyou would customize an LLM', 'start': 281.21, 'duration': 2.4}, {'text': 'for a Python to JavaScript app.', 'start': 283.61, 'duration': 2.797}, {'text': 'SPEAKER 2: Now, you\nmight be wondering', 'start': 286.407, 'duration': 1.583}, {'text': 'what the absolute best way\nto write a model prompt is.', 'start': 287.99, 'duration': 2.82}, {'text': "And if so, we've got\nsome bad news for you.", 'start': 290.81, 'duration': 2.738}, {'text': "SPEAKER 1: There's\ncurrently no optimal way", 'start': 293.548, 'duration': 1.792}, {'text': "to write model\nprompts, and that's", 'start': 295.34, 'duration': 1.26}, {'text': 'because the results we get\nare so highly dependent', 'start': 296.6, 'duration': 2.13}, {'text': 'on the underlying model.', 'start': 298.73, 'duration': 1.38}, {'text': 'Sometimes small changes in\nwording or even in word order', 'start': 300.11, 'duration': 2.85}, {'text': "can improve the LLM's outputs\nin ways that are not always", 'start': 302.96, 'duration': 2.7}, {'text': 'predictable.', 'start': 305.66, 'duration': 0.5}, {'text': "SPEAKER 2: That's\nwhy it's always worth", 'start': 306.16, 'duration': 1.625}, {'text': 'trying out lots of different\nstructures and examples', 'start': 307.785, 'duration': 2.195}, {'text': 'and formats and seeing what\nworks best for your use case.', 'start': 309.98, 'duration': 3.062}, {'text': 'SPEAKER 1: There you have it.', 'start': 313.042, 'duration': 1.208}, {'text': "That's the magic of\nLLMs in a nutshell.", 'start': 314.25, 'duration': 1.73}, {'text': 'SPEAKER 2: You can check\nout Bard at bard.google.com,', 'start': 315.98, 'duration': 2.64}, {'text': 'and definitely let us\nknow in the comments', 'start': 318.62, 'duration': 1.86}, {'text': "below what you're\nbuilding with LLMs.", 'start': 320.48, 'duration': 1.62}, {'text': '[MUSIC PLAYING]', 'start': 322.1, 'duration': 3.05}]